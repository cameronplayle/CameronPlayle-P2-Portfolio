---
title: "Machine Learning Model Project"
---

This Machine Learning Project was used to help predict diabetes among females patients among the Pima Indians.

```{r}


diabetes <- read.csv("C:/Users/cplay/Downloads/diabetes.csv")

diabetes <- na.omit(diabetes)
```

```{r}
head(diabetes)

diabetes$Glucose[diabetes$Glucose == 0] <- mean(diabetes$Glucose[diabetes$Glucose != 0], na.rm = TRUE)
diabetes$BloodPressure[diabetes$BloodPressure == 0] <- mean(diabetes$BloodPressure[diabetes$BloodPressure != 0], na.rm = TRUE)
diabetes$SkinThickness[diabetes$SkinThickness == 0] <- mean(diabetes$SkinThickness[diabetes$SkinThickness != 0], na.rm = TRUE)
diabetes$Insulin[diabetes$Insulin == 0] <- mean(diabetes$Insulin[diabetes$Insulin != 0], na.rm = TRUE)
diabetes$BMI[diabetes$BMI == 0] <- mean(diabetes$BMI[diabetes$BMI != 0], na.rm = TRUE)

```

```{r}
# Load the dataset
diabetes <- read.csv("C:/Users/cplay/Downloads/diabetes.csv")

# Replace zeros with NA for relevant columns
diabetes$Glucose[diabetes$Glucose == 0] <- NA
diabetes$BloodPressure[diabetes$BloodPressure == 0] <- NA
diabetes$SkinThickness[diabetes$SkinThickness == 0] <- NA
diabetes$Insulin[diabetes$Insulin == 0] <- NA
diabetes$BMI[diabetes$BMI == 0] <- NA

```

```{r}
# Replace NA values with the median of each column
diabetes$Glucose <- ifelse(is.na(diabetes$Glucose), 
                           median(diabetes$Glucose, na.rm = TRUE), 
                           diabetes$Glucose)
diabetes$BloodPressure <- ifelse(is.na(diabetes$BloodPressure), 
                                 median(diabetes$BloodPressure, na.rm = TRUE), 
                                 diabetes$BloodPressure)
diabetes$SkinThickness <- ifelse(is.na(diabetes$SkinThickness), 
                                 median(diabetes$SkinThickness, na.rm = TRUE), 
                                 diabetes$SkinThickness)
diabetes$Insulin <- ifelse(is.na(diabetes$Insulin), 
                           median(diabetes$Insulin, na.rm = TRUE), 
                           diabetes$Insulin)
diabetes$BMI <- ifelse(is.na(diabetes$BMI), 
                       median(diabetes$BMI, na.rm = TRUE), 
                       diabetes$BMI)

# View the processed data
summary(diabetes)
```

```{r}
# Load necessary libraries
library(ggplot2)
library(lattice)
library(caret)
library(e1071)

```

```{r}
set.seed(123)  # For reproducibility

# Split the data into training (70%) and testing (30%) sets
trainIndex <- createDataPartition(diabetes$Outcome, p = 0.7, list = FALSE)
diabetes_train <- diabetes[trainIndex, ]
diabetes_test <- diabetes[-trainIndex, ]
```

```{r}
# Train a logistic regression model
logistic_model <- glm(Outcome ~ ., data = diabetes_train, family = binomial)

# Summary of the model
summary(logistic_model)
```

```{r}
library(pROC)
# Generate predictions on the test set
# type = "response" gives predicted probabilities
predictions <- predict(logistic_model, newdata = diabetes_test, type = "response")

# Calculate the ROC curve
roc_curve <- roc(diabetes_test$Outcome, predictions)

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve for Logistic Regression Model")
abline(a = 0, b = 1, col = "red", lty = 2)  # Reference line
```

```{r}
# Calculate absolute values of coefficients
abs_coefs <- abs(coef(logistic_model))

# Create a data frame for plotting
var_imp_data <- data.frame(
  Variable = names(abs_coefs),
  Importance = abs_coefs
)

# Exclude the intercept for plotting
var_imp_data <- var_imp_data[-1, ]

# Plot using ggplot2
ggplot(var_imp_data, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Variable Importance in Logistic Regression",
       x = "Predictor",
       y = "Absolute Coefficient Value")

# Predict on the testing set
predictions <- predict(logistic_model, newdata = diabetes_test, type = "response")
```

```{r}
# Convert probabilities to binary outcomes
predicted_outcomes <- ifelse(predictions > 0.5, 1, 0)

# Confusion Matrix
confusion_matrix <- confusionMatrix(as.factor(predicted_outcomes), as.factor(diabetes_test$Outcome))
print(confusion_matrix)

# Calculate Accuracy, Precision, Recall, F1 Score
accuracy <- sum(predicted_outcomes == diabetes_test$Outcome) / nrow(diabetes_test)
precision <- confusion_matrix$byClass["Pos Pred Value"]
recall <- confusion_matrix$byClass["Sensitivity"]
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the evaluation metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", f1_score, "\n")

# Print model coefficients
print(coef(logistic_model))
```

```{r}
roc_curve <- roc(diabetes_test$Outcome, predictions)

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve for Logistic Regression Model")
abline(a = 0, b = 1, col = "red", lty = 2)  # Reference line

# Calculate and print the AUC
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

```{r}
### Decision Tree Model

library(rpart)

# Train a decision tree model
tree_model <- rpart(Outcome ~ ., data = diabetes_train, method = "class")

# Predict probabilities on the test set
tree_predictions <- predict(tree_model, newdata = diabetes_test, type = "prob")[,2]
```

```{r}
### Random Forest

# Ensure that Outcome is a factor
diabetes_train$Outcome <- as.factor(diabetes_train$Outcome)
diabetes_test$Outcome <- as.factor(diabetes_test$Outcome)
library(randomForest)

# Train a random forest model for classification
rf_model <- randomForest(Outcome ~ ., data = diabetes_train, ntree = 100)

# Predict probabilities on the test set
rf_predictions <- predict(rf_model, newdata = diabetes_test, type = "prob")[,2]
```

```{r}
### SVM Model

library(e1071)

# Train an SVM model

svm_model <- svm(Outcome ~ ., data = diabetes_train, probability = TRUE)

# Predict probabilities on the test set
svm_predictions <- predict(svm_model, newdata = diabetes_test, probability = TRUE)
svm_predictions <- attr(svm_predictions, "probabilities")[,2]
```

```{r}

# Logistic Regression ROC and AUC
roc_logistic <- roc(diabetes_test$Outcome, predictions)
auc_logistic <- auc(roc_logistic)

# Decision Tree ROC and AUC
roc_tree <- roc(diabetes_test$Outcome, tree_predictions)
auc_tree <- auc(roc_tree)

# Random Forest ROC and AUC
roc_rf <- roc(diabetes_test$Outcome, rf_predictions)
auc_rf <- auc(roc_rf)

# SVM ROC and AUC
roc_svm <- roc(diabetes_test$Outcome, svm_predictions)
auc_svm <- auc(roc_svm)

# Plot ROC Curves
plot(roc_logistic, col = "blue", main = "ROC Curves for Different Models")
plot(roc_tree, add = TRUE, col = "green")
plot(roc_rf, add = TRUE, col = "red")
plot(roc_svm, add = TRUE, col = "purple")
legend("bottomright", legend = c("Logistic Regression", "Decision Tree", "Random Forest", "SVM"),
       col = c("blue", "green", "red", "purple"), lwd = 2)

```

```{r}
# Print AUC values
cat("AUC for Logistic Regression:", auc_logistic, "\n")
cat("AUC for Decision Tree:", auc_tree, "\n")
cat("AUC for Random Forest:", auc_rf, "\n")
cat("AUC for SVM:", auc_svm, "\n")
```
